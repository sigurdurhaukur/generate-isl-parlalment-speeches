{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "all_paths = []\n",
    "for root, dirs, files in os.walk(\"./processed_data\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "             all_paths.append(os.path.join(root, file))\n",
    "\n",
    "# # initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# train it on the files\n",
    "tokenizer.train_from_iterator(all_paths, vocab_size=30000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./ice-tokenizer/vocab.json', './ice-tokenizer/merges.txt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a directory to save the tokenizer files\n",
    "os.makedirs(\"./ice-tokenizer\", exist_ok=True)\n",
    "\n",
    "# save it\n",
    "tokenizer.save_model(\"./ice-tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "# Load the tokenizer from the saved model directory\n",
    "tokenizer = ByteLevelBPETokenizer.from_file(\"./ice-tokenizer/vocab.json\", \"./ice-tokenizer/merges.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'v',\n",
       " 'a',\n",
       " '√É',\n",
       " '¬∞',\n",
       " 'ƒ†',\n",
       " 'e',\n",
       " 'r',\n",
       " 'ƒ†',\n",
       " 'a',\n",
       " '√É',\n",
       " '¬∞',\n",
       " 'ƒ†',\n",
       " 'fr',\n",
       " '√É',\n",
       " '¬©',\n",
       " 't',\n",
       " 'ta',\n",
       " 'ƒ†',\n",
       " '√∞',\n",
       " '≈Å',\n",
       " 'ƒ∫',\n",
       " 'ƒ£',\n",
       " 'ƒ†',\n",
       " '?']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Hva√∞ er a√∞ fr√©tta üòÅ ?').tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a8b61342504648af5e52a7055b0344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/16842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/haukur/.cache/huggingface/datasets/text/default-86be84e4b6fda226/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e559a725c84a0ab6fe2dbf47097e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "all_paths = []\n",
    "for root, dirs, files in os.walk(\"./processed_data\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "             all_paths.append(os.path.join(root, file))\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "portion = 0.01\n",
    "all_paths = all_paths[:int(len(all_paths) * portion)]\n",
    "# dataset = load_dataset('text', data_files=all_paths)\n",
    "\n",
    "# train and test split\n",
    "dataset = load_dataset('text', data_files=all_paths, split=['train[:80%]', 'train[80%:]'])\n",
    "\n",
    "train_dataset = dataset[0]\n",
    "test_dataset = dataset[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/haukur/.cache/huggingface/datasets/text/default-86be84e4b6fda226/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-4528f20a85756126.arrow\n",
      "Loading cached processed dataset at /home/haukur/.cache/huggingface/datasets/text/default-86be84e4b6fda226/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ecc09ff14ac58a69.arrow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "context_length = 1024\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenizer.enable_truncation(max_length=context_length)\n",
    "    tokenizer.enable_padding(length=context_length)\n",
    "\n",
    "    tokenized_examples = tokenizer.encode_batch(examples[\"text\"])\n",
    "\n",
    "    # result = {\"input_ids\": [tokenized_example.ids for tokenized_example in tokenized_examples], \"attention_mask\": [tokenized_example.attention_mask for tokenized_example in tokenized_examples]}\n",
    "\n",
    "    # to save space, we only save the input_ids\n",
    "    result = {\"input_ids\": [tokenized_example.ids for tokenized_example in tokenized_examples]}\n",
    "    return result\n",
    "\n",
    "tokanized_train_dataset = train_dataset.map(tokenize_function, batched=True, batch_size=1000, remove_columns=[\"text\"])\n",
    "tokanized_test_dataset = test_dataset.map(tokenize_function, batched=True, batch_size=1000, remove_columns=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['input_ids'],\n",
       "     num_rows: 13474\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text'],\n",
       "     num_rows: 13474\n",
       " }))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokanized_train_dataset, train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [42,\n",
       "  86,\n",
       "  132,\n",
       "  107,\n",
       "  88,\n",
       "  366,\n",
       "  225,\n",
       "  45,\n",
       "  82,\n",
       "  387,\n",
       "  88,\n",
       "  225,\n",
       "  38,\n",
       "  132,\n",
       "  104,\n",
       "  306,\n",
       "  86,\n",
       "  17,\n",
       "  225,\n",
       "  291,\n",
       "  225,\n",
       "  87,\n",
       "  90,\n",
       "  73,\n",
       "  77,\n",
       "  261,\n",
       "  86,\n",
       "  74,\n",
       "  132,\n",
       "  107,\n",
       "  80,\n",
       "  132,\n",
       "  119,\n",
       "  75,\n",
       "  225,\n",
       "  225,\n",
       "  225,\n",
       "  225,\n",
       "  58,\n",
       "  73,\n",
       "  75,\n",
       "  87,\n",
       "  80,\n",
       "  132,\n",
       "  116,\n",
       "  132,\n",
       "  113,\n",
       "  77,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  86,\n",
       "  132,\n",
       "  113,\n",
       "  89,\n",
       "  86,\n",
       "  225,\n",
       "  80,\n",
       "  69,\n",
       "  75,\n",
       "  132,\n",
       "  113,\n",
       "  89,\n",
       "  86,\n",
       "  225,\n",
       "  89,\n",
       "  84,\n",
       "  84,\n",
       "  225,\n",
       "  47,\n",
       "  89,\n",
       "  70,\n",
       "  70,\n",
       "  69,\n",
       "  16,\n",
       "  225,\n",
       "  715,\n",
       "  80,\n",
       "  80,\n",
       "  225,\n",
       "  132,\n",
       "  260,\n",
       "  225,\n",
       "  70,\n",
       "  83,\n",
       "  88,\n",
       "  82,\n",
       "  77,\n",
       "  225,\n",
       "  55,\n",
       "  401,\n",
       "  88,\n",
       "  89,\n",
       "  80,\n",
       "  87,\n",
       "  715,\n",
       "  86,\n",
       "  132,\n",
       "  113,\n",
       "  326,\n",
       "  16,\n",
       "  225,\n",
       "  83,\n",
       "  74,\n",
       "  427,\n",
       "  225,\n",
       "  44,\n",
       "  83,\n",
       "  80,\n",
       "  261,\n",
       "  76,\n",
       "  90,\n",
       "  73,\n",
       "  86,\n",
       "  438,\n",
       "  225,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  132,\n",
       "  240,\n",
       "  87,\n",
       "  69,\n",
       "  547,\n",
       "  132,\n",
       "  113,\n",
       "  77,\n",
       "  18,\n",
       "  225,\n",
       "  38,\n",
       "  132,\n",
       "  104,\n",
       "  306,\n",
       "  86,\n",
       "  342,\n",
       "  78,\n",
       "  132,\n",
       "  116,\n",
       "  86,\n",
       "  82,\n",
       "  225,\n",
       "  132,\n",
       "  240,\n",
       "  87,\n",
       "  69,\n",
       "  715,\n",
       "  86,\n",
       "  132,\n",
       "  113,\n",
       "  326,\n",
       "  70,\n",
       "  132,\n",
       "  104,\n",
       "  306,\n",
       "  86,\n",
       "  225,\n",
       "  87,\n",
       "  69,\n",
       "  81,\n",
       "  132,\n",
       "  127,\n",
       "  93,\n",
       "  79,\n",
       "  79,\n",
       "  88,\n",
       "  77,\n",
       "  225,\n",
       "  132,\n",
       "  260,\n",
       "  225,\n",
       "  262,\n",
       "  75,\n",
       "  225,\n",
       "  88,\n",
       "  77,\n",
       "  80,\n",
       "  80,\n",
       "  132,\n",
       "  119,\n",
       "  382,\n",
       "  225,\n",
       "  87,\n",
       "  79,\n",
       "  77,\n",
       "  84,\n",
       "  89,\n",
       "  80,\n",
       "  69,\n",
       "  75,\n",
       "  87,\n",
       "  17,\n",
       "  225,\n",
       "  291,\n",
       "  225,\n",
       "  429,\n",
       "  328,\n",
       "  281,\n",
       "  79,\n",
       "  306,\n",
       "  82,\n",
       "  73,\n",
       "  74,\n",
       "  82,\n",
       "  262,\n",
       "  86,\n",
       "  225,\n",
       "  132,\n",
       "  240,\n",
       "  87,\n",
       "  69,\n",
       "  715,\n",
       "  86,\n",
       "  132,\n",
       "  113,\n",
       "  326,\n",
       "  70,\n",
       "  132,\n",
       "  104,\n",
       "  306,\n",
       "  86,\n",
       "  225,\n",
       "  89,\n",
       "  81,\n",
       "  225,\n",
       "  132,\n",
       "  127,\n",
       "  78,\n",
       "  132,\n",
       "  116,\n",
       "  82,\n",
       "  89,\n",
       "  342,\n",
       "  89,\n",
       "  90,\n",
       "  73,\n",
       "  75,\n",
       "  225,\n",
       "  74,\n",
       "  93,\n",
       "  86,\n",
       "  281,\n",
       "  225,\n",
       "  87,\n",
       "  82,\n",
       "  78,\n",
       "  132,\n",
       "  116,\n",
       "  74,\n",
       "  80,\n",
       "  132,\n",
       "  116,\n",
       "  132,\n",
       "  113,\n",
       "  920,\n",
       "  326,\n",
       "  82,\n",
       "  326,\n",
       "  75,\n",
       "  86,\n",
       "  507,\n",
       "  72,\n",
       "  89,\n",
       "  86,\n",
       "  225,\n",
       "  87,\n",
       "  73,\n",
       "  81,\n",
       "  225,\n",
       "  342,\n",
       "  384,\n",
       "  72,\n",
       "  89,\n",
       "  86,\n",
       "  225,\n",
       "  88,\n",
       "  77,\n",
       "  80,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  86,\n",
       "  73,\n",
       "  280,\n",
       "  69,\n",
       "  18,\n",
       "  225,\n",
       "  58,\n",
       "  73,\n",
       "  86,\n",
       "  79,\n",
       "  132,\n",
       "  260,\n",
       "  87,\n",
       "  16,\n",
       "  225,\n",
       "  87,\n",
       "  73,\n",
       "  81,\n",
       "  225,\n",
       "  87,\n",
       "  132,\n",
       "  107,\n",
       "  86,\n",
       "  225,\n",
       "  89,\n",
       "  81,\n",
       "  225,\n",
       "  76,\n",
       "  132,\n",
       "  119,\n",
       "  82,\n",
       "  82,\n",
       "  359,\n",
       "  225,\n",
       "  342,\n",
       "  83,\n",
       "  132,\n",
       "  113,\n",
       "  90,\n",
       "  281,\n",
       "  79,\n",
       "  306,\n",
       "  82,\n",
       "  82,\n",
       "  69,\n",
       "  16,\n",
       "  225,\n",
       "  80,\n",
       "  69,\n",
       "  75,\n",
       "  132,\n",
       "  113,\n",
       "  77,\n",
       "  225,\n",
       "  298,\n",
       "  69,\n",
       "  81,\n",
       "  225,\n",
       "  88,\n",
       "  90,\n",
       "  132,\n",
       "  104,\n",
       "  86,\n",
       "  225,\n",
       "  88,\n",
       "  77,\n",
       "  80,\n",
       "  80,\n",
       "  132,\n",
       "  119,\n",
       "  383,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  75,\n",
       "  77,\n",
       "  225,\n",
       "  74,\n",
       "  93,\n",
       "  86,\n",
       "  281,\n",
       "  225,\n",
       "  87,\n",
       "  79,\n",
       "  77,\n",
       "  84,\n",
       "  89,\n",
       "  80,\n",
       "  69,\n",
       "  75,\n",
       "  87,\n",
       "  17,\n",
       "  225,\n",
       "  291,\n",
       "  225,\n",
       "  429,\n",
       "  328,\n",
       "  281,\n",
       "  79,\n",
       "  306,\n",
       "  82,\n",
       "  73,\n",
       "  74,\n",
       "  82,\n",
       "  72,\n",
       "  225,\n",
       "  132,\n",
       "  240,\n",
       "  87,\n",
       "  69,\n",
       "  715,\n",
       "  86,\n",
       "  132,\n",
       "  113,\n",
       "  326,\n",
       "  70,\n",
       "  132,\n",
       "  104,\n",
       "  306,\n",
       "  86,\n",
       "  225,\n",
       "  291,\n",
       "  225,\n",
       "  90,\n",
       "  69,\n",
       "  80,\n",
       "  72,\n",
       "  77,\n",
       "  225,\n",
       "  82,\n",
       "  73,\n",
       "  74,\n",
       "  82,\n",
       "  546,\n",
       "  225,\n",
       "  132,\n",
       "  127,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  87,\n",
       "  73,\n",
       "  81,\n",
       "  225,\n",
       "  76,\n",
       "  132,\n",
       "  123,\n",
       "  82,\n",
       "  225,\n",
       "  261,\n",
       "  80,\n",
       "  72,\n",
       "  77,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  93,\n",
       "  514,\n",
       "  225,\n",
       "  81,\n",
       "  507,\n",
       "  82,\n",
       "  69,\n",
       "  225,\n",
       "  87,\n",
       "  78,\n",
       "  132,\n",
       "  99,\n",
       "  69,\n",
       "  368,\n",
       "  73,\n",
       "  382,\n",
       "  225,\n",
       "  293,\n",
       "  79,\n",
       "  77,\n",
       "  18,\n",
       "  225,\n",
       "  56,\n",
       "  77,\n",
       "  80,\n",
       "  225,\n",
       "  342,\n",
       "  384,\n",
       "  72,\n",
       "  89,\n",
       "  86,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  81,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  132,\n",
       "  123,\n",
       "  88,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  75,\n",
       "  507,\n",
       "  82,\n",
       "  225,\n",
       "  73,\n",
       "  74,\n",
       "  366,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  89,\n",
       "  84,\n",
       "  84,\n",
       "  87,\n",
       "  297,\n",
       "  82,\n",
       "  507,\n",
       "  382,\n",
       "  225,\n",
       "  342,\n",
       "  83,\n",
       "  132,\n",
       "  113,\n",
       "  90,\n",
       "  281,\n",
       "  79,\n",
       "  306,\n",
       "  82,\n",
       "  82,\n",
       "  69,\n",
       "  225,\n",
       "  80,\n",
       "  132,\n",
       "  126,\n",
       "  401,\n",
       "  86,\n",
       "  18,\n",
       "  225,\n",
       "  56,\n",
       "  77,\n",
       "  80,\n",
       "  80,\n",
       "  132,\n",
       "  119,\n",
       "  382,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  75,\n",
       "  507,\n",
       "  89,\n",
       "  81,\n",
       "  225,\n",
       "  81,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  87,\n",
       "  78,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  132,\n",
       "  260,\n",
       "  225,\n",
       "  398,\n",
       "  132,\n",
       "  113,\n",
       "  76,\n",
       "  384,\n",
       "  75,\n",
       "  77,\n",
       "  225,\n",
       "  81,\n",
       "  73,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  298,\n",
       "  132,\n",
       "  107,\n",
       "  88,\n",
       "  88,\n",
       "  507,\n",
       "  82,\n",
       "  77,\n",
       "  18,\n",
       "  225,\n",
       "  132,\n",
       "  253,\n",
       "  88,\n",
       "  74,\n",
       "  132,\n",
       "  104,\n",
       "  86,\n",
       "  87,\n",
       "  80,\n",
       "  69,\n",
       "  225,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  87,\n",
       "  82,\n",
       "  78,\n",
       "  132,\n",
       "  116,\n",
       "  74,\n",
       "  80,\n",
       "  132,\n",
       "  116,\n",
       "  132,\n",
       "  113,\n",
       "  920,\n",
       "  132,\n",
       "  119,\n",
       "  86,\n",
       "  82,\n",
       "  89,\n",
       "  81,\n",
       "  225,\n",
       "  132,\n",
       "  260,\n",
       "  225,\n",
       "  47,\n",
       "  89,\n",
       "  70,\n",
       "  70,\n",
       "  69,\n",
       "  225,\n",
       "  76,\n",
       "  73,\n",
       "  74,\n",
       "  89,\n",
       "  86,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  86,\n",
       "  77,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  89,\n",
       "  81,\n",
       "  72,\n",
       "  73,\n",
       "  77,\n",
       "  80,\n",
       "  72,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  75,\n",
       "  82,\n",
       "  69,\n",
       "  225,\n",
       "  132,\n",
       "  127,\n",
       "  73,\n",
       "  271,\n",
       "  225,\n",
       "  80,\n",
       "  132,\n",
       "  126,\n",
       "  88,\n",
       "  280,\n",
       "  225,\n",
       "  87,\n",
       "  73,\n",
       "  81,\n",
       "  225,\n",
       "  342,\n",
       "  83,\n",
       "  132,\n",
       "  113,\n",
       "  90,\n",
       "  281,\n",
       "  79,\n",
       "  507,\n",
       "  16,\n",
       "  225,\n",
       "  132,\n",
       "  99,\n",
       "  87,\n",
       "  69,\n",
       "  81,\n",
       "  88,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  75,\n",
       "  507,\n",
       "  89,\n",
       "  81,\n",
       "  16,\n",
       "  225,\n",
       "  90,\n",
       "  69,\n",
       "  80,\n",
       "  262,\n",
       "  225,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  715,\n",
       "  80,\n",
       "  80,\n",
       "  507,\n",
       "  89,\n",
       "  18,\n",
       "  225,\n",
       "  44,\n",
       "  83,\n",
       "  80,\n",
       "  261,\n",
       "  76,\n",
       "  90,\n",
       "  73,\n",
       "  86,\n",
       "  74,\n",
       "  77,\n",
       "  16,\n",
       "  225,\n",
       "  87,\n",
       "  73,\n",
       "  81,\n",
       "  225,\n",
       "  513,\n",
       "  75,\n",
       "  383,\n",
       "  225,\n",
       "  359,\n",
       "  72,\n",
       "  281,\n",
       "  225,\n",
       "  47,\n",
       "  89,\n",
       "  70,\n",
       "  70,\n",
       "  69,\n",
       "  16,\n",
       "  225,\n",
       "  73,\n",
       "  86,\n",
       "  225,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  87,\n",
       "  90,\n",
       "  83,\n",
       "  79,\n",
       "  132,\n",
       "  119,\n",
       "  80,\n",
       "  80,\n",
       "  89,\n",
       "  132,\n",
       "  113,\n",
       "  89,\n",
       "  225,\n",
       "  76,\n",
       "  132,\n",
       "  104,\n",
       "  88,\n",
       "  88,\n",
       "  89,\n",
       "  87,\n",
       "  90,\n",
       "  132,\n",
       "  104,\n",
       "  132,\n",
       "  113,\n",
       "  77,\n",
       "  225,\n",
       "  39,\n",
       "  225,\n",
       "  87,\n",
       "  73,\n",
       "  81,\n",
       "  225,\n",
       "  70,\n",
       "  73,\n",
       "  86,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  86,\n",
       "  306,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  74,\n",
       "  89,\n",
       "  80,\n",
       "  80,\n",
       "  89,\n",
       "  225,\n",
       "  73,\n",
       "  132,\n",
       "  113,\n",
       "  69,\n",
       "  225,\n",
       "  373,\n",
       "  89,\n",
       "  84,\n",
       "  69,\n",
       "  225,\n",
       "  89,\n",
       "  84,\n",
       "  84,\n",
       "  225,\n",
       "  87,\n",
       "  90,\n",
       "  83,\n",
       "  225,\n",
       "  384,\n",
       "  75,\n",
       "  281,\n",
       "  225,\n",
       "  132,\n",
       "  260,\n",
       "  70,\n",
       "  132,\n",
       "  123,\n",
       "  326,\n",
       "  225,\n",
       "  70,\n",
       "  132,\n",
       "  123,\n",
       "  77,\n",
       "  225,\n",
       "  132,\n",
       "  99,\n",
       "  225,\n",
       "  87,\n",
       "  82,\n",
       "  78,\n",
       "  132,\n",
       "  116,\n",
       "  74,\n",
       "  80,\n",
       "  132,\n",
       "  116,\n",
       "  132,\n",
       "  113,\n",
       "  69,\n",
       "  76,\n",
       "  132,\n",
       "  104,\n",
       "  88,\n",
       "  88,\n",
       "  89,\n",
       "  87,\n",
       "  90,\n",
       "  132,\n",
       "  104,\n",
       "  132,\n",
       "  113,\n",
       "  77,\n",
       "  18,\n",
       "  225,\n",
       "  49,\n",
       "  507,\n",
       "  82,\n",
       "  77,\n",
       "  76,\n",
       "  80,\n",
       "  89,\n",
       "  88,\n",
       "  77,\n",
       "  225,\n",
       "  70,\n",
       "  132,\n",
       "  104,\n",
       "  306,\n",
       "  86,\n",
       "  342,\n",
       "  78,\n",
       "  132,\n",
       "  116,\n",
       "  86,\n",
       "  82,\n",
       "  326,\n",
       "  225,\n",
       "  132,\n",
       "  116,\n",
       "  386,\n",
       "  132,\n",
       "  113,\n",
       "  77,\n",
       "  225,\n",
       "  73,\n",
       "  74,\n",
       "  366,\n",
       "  225,\n",
       "  132,\n",
       "  127,\n",
       "  90,\n",
       "  132,\n",
       "  260,\n",
       "  225,\n",
       "  132,\n",
       "  260,\n",
       "  225,\n",
       "  262,\n",
       "  75,\n",
       "  225,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  81,\n",
       "  132,\n",
       "  99,\n",
       "  80,\n",
       "  507,\n",
       "  89,\n",
       "  225,\n",
       "  93,\n",
       "  86,\n",
       "  132,\n",
       "  113,\n",
       "  77,\n",
       "  225,\n",
       "  298,\n",
       "  73,\n",
       "  87,\n",
       "  261,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  291,\n",
       "  225,\n",
       "  89,\n",
       "  84,\n",
       "  84,\n",
       "  80,\n",
       "  132,\n",
       "  126,\n",
       "  87,\n",
       "  507,\n",
       "  75,\n",
       "  69,\n",
       "  225,\n",
       "  69,\n",
       "  74,\n",
       "  80,\n",
       "  69,\n",
       "  132,\n",
       "  113,\n",
       "  225,\n",
       "  89,\n",
       "  81,\n",
       "  225,\n",
       "  87,\n",
       "  69,\n",
       "  81,\n",
       "  70,\n",
       "  132,\n",
       "  104,\n",
       "  86,\n",
       "  77,\n",
       "  80,\n",
       "  73,\n",
       "  75,\n",
       "  69,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  75,\n",
       "  77,\n",
       "  16,\n",
       "  225,\n",
       "  76,\n",
       "  90,\n",
       "  73,\n",
       "  86,\n",
       "  82,\n",
       "  77,\n",
       "  75,\n",
       "  225,\n",
       "  132,\n",
       "  127,\n",
       "  73,\n",
       "  281,\n",
       "  225,\n",
       "  76,\n",
       "  69,\n",
       "  74,\n",
       "  77,\n",
       "  225,\n",
       "  90,\n",
       "  73,\n",
       "  86,\n",
       "  77,\n",
       "  132,\n",
       "  ...]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokanized_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "# Initializing a GPT2 configuration\n",
    "configuration = GPT2Config(vocab_size=30000, \n",
    "                           n_ctx=context_length, \n",
    "                        #    bos_token_id=0, \n",
    "                        #    eos_token_id=0, \n",
    "                        #    pad_token_id=0, \n",
    "                           n_positions=context_length)\n",
    "\n",
    "# Initializing a model from the configuration\n",
    "model = GPT2LMHeadModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.30.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30000\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICE GPT-2 size: 108.9M parameters\n"
     ]
    }
   ],
   "source": [
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"ICE GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.eos_token = \"<|endoftext|>\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haukur/miniconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ByteLevelBPETokenizer' object has no attribute 'pad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 31\u001b[0m\n\u001b[1;32m      5\u001b[0m args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      6\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mice-gpt2\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     fp16\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     23\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     24\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     25\u001b[0m     args\u001b[39m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1642\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1643\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1644\u001b[0m )\n\u001b[0;32m-> 1645\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1646\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1647\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1648\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1649\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1650\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:1916\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1915\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 1916\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1917\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1918\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/data/data_collator.py:45\u001b[0m, in \u001b[0;36mDataCollatorMixin.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_call(features)\n\u001b[1;32m     44\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_call(features)\n\u001b[1;32m     46\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnp\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy_call(features)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/data/data_collator.py:732\u001b[0m, in \u001b[0;36mDataCollatorForLanguageModeling.torch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtorch_call\u001b[39m(\u001b[39mself\u001b[39m, examples: List[Union[List[\u001b[39mint\u001b[39m], Any, Dict[\u001b[39mstr\u001b[39m, Any]]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    730\u001b[0m     \u001b[39m# Handle dict or lists with proper padding and conversion to tensor.\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(examples[\u001b[39m0\u001b[39m], Mapping):\n\u001b[0;32m--> 732\u001b[0m         batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad(examples, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, pad_to_multiple_of\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_to_multiple_of)\n\u001b[1;32m    733\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m         batch \u001b[39m=\u001b[39m {\n\u001b[1;32m    735\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: _torch_collate_batch(examples, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, pad_to_multiple_of\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_to_multiple_of)\n\u001b[1;32m    736\u001b[0m         }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ByteLevelBPETokenizer' object has no attribute 'pad'"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"ice-gpt2\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokanized_train_dataset,\n",
    "    eval_dataset=tokanized_test_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m---> 23\u001b[0m     batch \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     24\u001b[0m     inputs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: batch[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m: batch[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[45], line 23\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m---> 23\u001b[0m     batch \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39;49mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     24\u001b[0m     inputs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: batch[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m: batch[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define your training parameters\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 5e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create DataLoader for your training dataset\n",
    "train_dataloader = DataLoader(tokanized_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Set up your model and optimizer\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        inputs = {\"input_ids\": batch[\"input_ids\"], \"labels\": batch[\"input_ids\"]}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Average Loss = {average_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
